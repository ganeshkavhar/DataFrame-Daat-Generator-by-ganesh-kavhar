
from pyspark.sql import SparkSession
from pyspark.sql.functions import col
import random
import string

# Initialize SparkSession
spark = SparkSession.builder.appName("EmployeeDaatabasebyganeshkavhar").master("local[*]").getOrCreate()

# Function to generate random names
def random_name(length=5):
    return ''.join(random.choice(string.ascii_letters) for _ in range(length))

# Function to generate random salaries
def random_salary():
    return random.randint(30000, 150000)

# Create a list of dictionaries with more than 100 employee records
employees = [{"id": i, "name": random_name(), "age": random.randint(20, 60), "department": random.choice(["HR", "Finance", "IT", "Marketing"]), "salary": random_salary()} for i in range(101)]

# Create a PySpark DataFrame from the list of dictionaries
df = spark.createDataFrame(employees)

# Show the DataFrame
df.show()

# Perform some operations to verify
# For example: Filter employees with salary greater than 100,000
high_salary_df = df.filter(col("salary") > 100000)
high_salary_df.show()
